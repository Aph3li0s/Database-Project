{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, MetaData, inspect,Table, text\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "#Check if folders exist or not, if not create folders\n",
    "path = 'data/tables_csv'\n",
    "check = os.path.exists(path)\n",
    "if not check:\n",
    "    os.makedirs(path)\n",
    "\n",
    "path = 'data/duplicate'\n",
    "check = os.path.exists(path)\n",
    "if not check:\n",
    "    os.makedirs(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#Read excel files and assigned it to variables\n",
    "mn = pd.read_excel('data/edited_data/mn_edit.xlsx', header=0)\n",
    "th = pd.read_excel('data/edited_data/th_edit.xlsx', header=0)\n",
    "thcs = pd.read_excel('data/edited_data/thcs_edit.xlsx', header=0)\n",
    "thpt = pd.read_excel('data/edited_data/thpt_edit.xlsx', header=0)\n",
    "gdtx = pd.read_excel('data/edited_data/gdtx_edit.xlsx', header=0)\n",
    "\n",
    "ph_gd = pd.read_excel('data/edited_data/dm_phong_gd.xlsx', header=0)\n",
    "cap_trg = pd.read_excel('data/edited_data/dm_cap_truong.xlsx', header=0)\n",
    "loai_trg = pd.read_excel('data/edited_data/dm_loai_truong.xlsx', header=0)\n",
    "loai_hinh = pd.read_excel('data/edited_data/dm_loai_hinh.xlsx', header=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ph_gd.to_csv('data/tables_csv/phong_gd.csv', index = False)\n",
    "cap_trg.to_csv('data/tables_csv/cap_truong.csv', index = False)\n",
    "loai_trg.to_csv('data/tables_csv/loai_truong.csv', index = False)\n",
    "loai_hinh.to_csv('data/tables_csv/loai_hinh.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "#Add a column to thpt and gdtx\n",
    "col = \"Phong_GDDT\"\n",
    "if col not in thpt.columns:\n",
    "    thpt.insert(3, col, None)\n",
    "if col not in gdtx.columns:\n",
    "    gdtx.insert(3, col, None)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schools in total (include duplicated schools):\n",
      "4347\n"
     ]
    }
   ],
   "source": [
    "#Check how many rows in total (5 tables)\n",
    "print(\"Schools in total (include duplicated schools):\")\n",
    "print(len(mn) + len(th) + len(thcs) + len(thpt) + len(gdtx))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#Merge 5 files (school stages) and create a new csv file Schools - the first main table\n",
    "table1_col = ['Ma_truong', 'Ten_truong','Dia_chi']\n",
    "table1  = pd.concat([mn[table1_col], th[table1_col], thcs[table1_col], thpt[table1_col], gdtx[table1_col]], axis=0).drop_duplicates(subset='Ma_truong', keep = 'first')\n",
    "table1.to_csv('data/tables_csv/Schools.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "#Adding additional column for my purpose\n",
    "col = \"Cap_truong\"\n",
    "if col not in mn.columns:\n",
    "    mn.insert(2, col, \"Mầm non\", True)\n",
    "if col not in th.columns:\n",
    "    th.insert(2, col, \"Tiểu học\", True)\n",
    "if col not in thcs.columns:\n",
    "    thcs.insert(2, col, \"Trung học cơ sở\", True)\n",
    "if col not in thpt.columns:\n",
    "    thpt.insert(2, col, \"Trung học phổ thông\", True)\n",
    "if col not in gdtx.columns:\n",
    "    gdtx.insert(2, col, \"Giáo dục thường xuyên\", True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#Create a csv file School_stages, this is my 2nd main table\n",
    "table2_col = ['Ma_truong', 'Phong_GDDT','Loai_hinh', 'Loai_truong', 'Cap_truong']\n",
    "table2  = pd.concat([mn[table2_col], th[table2_col], thcs[table2_col], thpt[table2_col], gdtx[table2_col]], axis=0)\n",
    "table2.to_csv('data/tables_csv/School_stages.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "#I used map to reference to my indexing table\n",
    "a = dict(zip(ph_gd['Ten_phgd'], ph_gd['id_ten']))\n",
    "table2['Phong_GDDT'] = table2['Phong_GDDT'].map(a)\n",
    "table2[\"Phong_GDDT\"] = table2[\"Phong_GDDT\"].fillna(\"Không\")\n",
    "\n",
    "b = dict(zip(loai_trg['Ten_ltrg'], loai_trg['id_ltrg']))\n",
    "table2['Loai_truong'] = table2['Loai_truong'].map(b)\n",
    "\n",
    "c = dict(zip(loai_hinh['Ten_lhinh'], loai_hinh['id_lhinh']))\n",
    "table2['Loai_hinh'] = table2['Loai_hinh'].map(c)\n",
    "\n",
    "d = dict(zip(cap_trg['Ten_captrg'], cap_trg['id_ct']))\n",
    "table2['Cap_truong'] = table2['Cap_truong'].map(d)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#This code is to check if Phong_GDDT still have any <null> values or not\n",
    "cnt2 = table2['Phong_GDDT'].isnull().sum()\n",
    "print(cnt2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "table2.to_csv('data/tables_csv/School_stages.csv', index = False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "#Print duplicate records into csv file\n",
    "#All schools that have more than one school stage will be listed in a duplicate file\n",
    "dup_schools  = pd.concat([mn[table1_col], th[table1_col], thcs[table1_col], thpt[table1_col], gdtx[table1_col]], axis=0)\n",
    "a = dup_schools[dup_schools.duplicated()]\n",
    "a.sort_values('Ma_truong').drop_duplicates(subset='Ma_truong', keep = 'first').to_csv('data/duplicate/dup_schools.csv', index= False)\n",
    "print(len(pd.read_csv('data/duplicate/dup_schools.csv')))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#Connect to mysql server with username = root\n",
    "engine = create_engine('mysql+mysqlconnector://root:22942294tram@localhost:3306/truonghoc')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "#Delete records from tables\n",
    "#I want to clean all the previous data before importing new ones\n",
    "connection = engine.connect()\n",
    "metadata = MetaData()\n",
    "inspector = inspect(engine)\n",
    "for table_name in reversed(inspector.get_table_names()):\n",
    "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
    "    connection = engine.connect()\n",
    "    delete_stmt = table.delete()\n",
    "    connection.execute(delete_stmt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "#Read csv files (files those will add data to database\n",
    "schools = pd.read_csv('data/tables_csv/Schools.csv')\n",
    "school_stages = pd.read_csv('data/tables_csv/School_stages.csv')\n",
    "phong_gd = pd.read_csv('data/tables_csv/phong_gd.csv')\n",
    "loai_hinh = pd.read_csv('data/tables_csv/loai_hinh.csv')\n",
    "loai_trg = pd.read_csv('data/tables_csv/loai_truong.csv')\n",
    "cap_trg = pd.read_csv('data/tables_csv/cap_truong.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "#Check if folders exist or not, if not create folders\n",
    "sql_file = \"\"\n",
    "def clean_file():\n",
    "    if os.stat(sql_file).st_size != 0:\n",
    "        with open(sql_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "#Import command to .sql file\n",
    "sql_file = 'sql_command/cap_truong.sql'\n",
    "query = \"INSERT INTO cap_truong (id_ct, ten_captrg) VALUES ('{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in cap_trg.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")\n",
    "\n",
    "sql_file = 'sql_command/loai_hinh.sql'\n",
    "query = \"INSERT INTO loai_hinh (id_lhinh, ten_lhinh) VALUES ('{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in loai_hinh.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")\n",
    "\n",
    "sql_file = 'sql_command/loai_truong.sql'\n",
    "query = \"INSERT INTO loai_truong (id_ltrg, ten_ltrg) VALUES ('{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in loai_trg.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")\n",
    "\n",
    "sql_file = 'sql_command/phong_gd.sql'\n",
    "query = \"INSERT INTO phong_gd (id_ten, ten_phgd) VALUES ('{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in phong_gd.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")\n",
    "\n",
    "sql_file = 'sql_command/schools.sql'\n",
    "query = \"INSERT INTO schools (ma_truong, ten_truong, dia_chi) VALUES ('{}', '{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in schools.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")\n",
    "\n",
    "sql_file = \"sql_command/school_stages.sql\"\n",
    "query = \"INSERT INTO school_stages (ma_truong, phong_gddt, loai_hinh, loai_truong, cap_truong) VALUES ('{}', '{}', '{}', '{}', '{}')\"\n",
    "clean_file()\n",
    "\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    for row in school_stages.itertuples(index=False):\n",
    "        f.write(query.format(*row))\n",
    "        f.write(\";\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "#I exported a file named execute_sql.txt. Just copy all of that and patse to sql command line, it will do the job\n",
    "src_dir = \"source C:/Users/ADMIN/Desktop/IT004_Project/Phan_1b/CreateSchema.sql\"\n",
    "dir = \"C:/Users/ADMIN/Desktop/IT004_Project/Phan_2/sql_command\"\n",
    "sql_file = 'execute_sql.txt'\n",
    "clean_file()\n",
    "with open(sql_file, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\")\n",
    "    f.write(src_dir)\n",
    "    f.write(\"\\n\")\n",
    "    for filename in os.listdir(dir):\n",
    "        link = os.path.join(dir, filename)\n",
    "        if os.path.isfile(link):\n",
    "            f.write(\"source \" + link)\n",
    "            f.write(\"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
